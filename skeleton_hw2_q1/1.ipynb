{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "5f92321701a46d45"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.097534Z",
     "start_time": "2026-01-04T16:39:07.084739Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from medmnist import BloodMNIST, INFO\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "data_flag = \"bloodmnist\"\n",
    "info = INFO[data_flag]\n",
    "n_classes = len(info[\"label\"])\n",
    "print(\"Classes:\", n_classes, info[\"label\"])"
   ],
   "id": "207e5f0a1b8281e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Classes: 8 {'0': 'basophil', '1': 'eosinophil', '2': 'erythroblast', '3': 'immature granulocytes(myelocytes, metamyelocytes and promyelocytes)', '4': 'lymphocyte', '5': 'monocyte', '6': 'neutrophil', '7': 'platelet'}\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.259055Z",
     "start_time": "2026-01-04T16:39:07.253460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5])\n",
    "])\n"
   ],
   "id": "84fd6f0ec4694a72",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plot Funtions",
   "id": "d6f8d9738f2c5096"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.316736Z",
     "start_time": "2026-01-04T16:39:07.311499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot(x, y, ylabel=\"\", name=\"\"):\n",
    "    plt.clf()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.plot(list(x), y)\n",
    "    plt.savefig(f\"{name}.pdf\", bbox_inches=\"tight\")\n"
   ],
   "id": "1c4f971945b590ae",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.331837Z",
     "start_time": "2026-01-04T16:39:07.327639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_compare(x, series_dict, ylabel=\"\", title=\"\", filename=\"compare\"):\n",
    "    plt.clf()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    for label, y in series_dict.items():\n",
    "        plt.plot(list(x), y, label=label)\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"{filename}.pdf\", bbox_inches=\"tight\")"
   ],
   "id": "c035a6268ea9320c",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN model",
   "id": "3ec67e2b5b274656"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.351493Z",
     "start_time": "2026-01-04T16:39:07.343926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=8, use_pool=True):\n",
    "        super().__init__()\n",
    "        self.use_pool = use_pool\n",
    "\n",
    "        # Convs iguais para os dois cenários\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, stride=1, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Heads diferentes porque o flatten muda\n",
    "        self.fc1_pool = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2_pool = nn.Linear(256, num_classes)\n",
    "\n",
    "        self.fc1_nopool = nn.Linear(128 * 28 * 28, 256)\n",
    "        self.fc2_nopool = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x, use_pool=None):\n",
    "        if use_pool is None:\n",
    "            use_pool = self.use_pool\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        if use_pool:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        if use_pool:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        if use_pool:\n",
    "            x = self.pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        if use_pool:\n",
    "            x = F.relu(self.fc1_pool(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2_pool(x)\n",
    "        else:\n",
    "            x = F.relu(self.fc1_nopool(x))\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc2_nopool(x)\n",
    "\n",
    "        return x"
   ],
   "id": "312e379d0936fc33",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Train Epoch",
   "id": "1e3c3eab16773a02"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.370641Z",
     "start_time": "2026-01-04T16:39:07.362624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(loader, model, criterion, optimizer, use_pool_flag):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for imgs, labels in loader:\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.squeeze().long().to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(imgs, use_pool=use_pool_flag)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(loader)\n"
   ],
   "id": "615a2c771501b8d0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluate",
   "id": "6b4d697bdd7592e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.390402Z",
     "start_time": "2026-01-04T16:39:07.383018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate_both(loader, model, use_pool_flag):\n",
    "    \"\"\"\n",
    "    Devolve (acc_sem_softmax, acc_com_softmax).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    preds_no_soft, preds_soft, targets = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.squeeze().long().to(device)\n",
    "\n",
    "            logits = model(imgs, use_pool=use_pool_flag)\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "\n",
    "            preds_no_soft += logits.argmax(dim=1).cpu().tolist()\n",
    "            preds_soft    += probs.argmax(dim=1).cpu().tolist()\n",
    "            targets       += labels.cpu().tolist()\n",
    "\n",
    "    acc_no_soft = accuracy_score(targets, preds_no_soft)\n",
    "    acc_soft    = accuracy_score(targets, preds_soft)\n",
    "    return acc_no_soft, acc_soft"
   ],
   "id": "35dea3904d24b3f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:39:07.406509Z",
     "start_time": "2026-01-04T16:39:07.401648Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ],
   "id": "15f36c7e4e9f6d08",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inicialização do modelo",
   "id": "61bd9ae2c0eedaf5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T16:40:06.120573Z",
     "start_time": "2026-01-04T16:39:07.436428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 64\n",
    "train_dataset = BloodMNIST(split=\"train\", transform=transform, download=True, size=28)\n",
    "val_dataset   = BloodMNIST(split=\"val\",   transform=transform, download=True, size=28)\n",
    "test_dataset  = BloodMNIST(split=\"test\",  transform=transform, download=True, size=28)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "epochs = 200\n",
    "lr = 1e-3\n",
    "use_pooling_flags = [False, True]\n",
    "\n",
    "results = {\n",
    "    \"train_loss\": {},\n",
    "    \"val_acc_no_soft\": {},\n",
    "    \"val_acc_soft\": {},\n",
    "    \"test_acc_no_soft\": {},\n",
    "    \"test_acc_soft\": {},\n",
    "    \"time_sec\": {},\n",
    "    \"params\": {}\n",
    "}\n",
    "\n",
    "global_start = time.time()\n",
    "\n",
    "for pool_flag in use_pooling_flags:\n",
    "    tag = \"with_pooling\" if pool_flag else \"no_pooling\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"EXPERIMENT:\", tag)\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    model = CNN(num_classes=n_classes, use_pool=pool_flag).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(\"Trainable params:\", count_params(model))\n",
    "\n",
    "    train_losses = []\n",
    "    val_no_soft_list = []\n",
    "    val_soft_list = []\n",
    "\n",
    "    exp_start = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        t0 = time.time()\n",
    "\n",
    "        tr_loss = train_epoch(train_loader, model, criterion, optimizer, use_pool_flag=pool_flag)\n",
    "        val_no_soft, val_soft = evaluate_both(val_loader, model, use_pool_flag=pool_flag)\n",
    "\n",
    "        train_losses.append(tr_loss)\n",
    "        val_no_soft_list.append(val_no_soft)\n",
    "        val_soft_list.append(val_soft)\n",
    "\n",
    "        dt = time.time() - t0\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:03d}/{epochs} | \"\n",
    "            f\"Loss: {tr_loss:.4f} | \"\n",
    "            f\"ValAcc no-soft: {val_no_soft:.4f} | \"\n",
    "            f\"ValAcc soft: {val_soft:.4f} | \"\n",
    "            f\"Time: {dt:.2f}s\"\n",
    "        )\n",
    "\n",
    "    test_no_soft, test_soft = evaluate_both(test_loader, model, use_pool_flag=pool_flag)\n",
    "    exp_time = time.time() - exp_start\n",
    "\n",
    "    print(f\"TestAcc no-soft: {test_no_soft:.4f} | TestAcc soft: {test_soft:.4f}\")\n",
    "    print(f\"Total time ({tag}): {exp_time/60:.2f} min ({exp_time:.2f} s)\")\n",
    "\n",
    "    # Save model uniquely (avoid overwrite)\n",
    "    torch.save(model.state_dict(), f\"bloodmnist_cnn_{tag}.pth\")\n",
    "    print(f\"Saved: bloodmnist_cnn_{tag}.pth\")\n",
    "\n",
    "    # Store results\n",
    "    results[\"train_loss\"][tag] = train_losses\n",
    "    results[\"val_acc_no_soft\"][tag] = val_no_soft_list\n",
    "    results[\"val_acc_soft\"][tag] = val_soft_list\n",
    "    results[\"test_acc_no_soft\"][tag] = test_no_soft\n",
    "    results[\"test_acc_soft\"][tag] = test_soft\n",
    "    results[\"time_sec\"][tag] = exp_time\n",
    "    results[\"params\"][tag] = count_params(model)\n",
    "\n",
    "    # Per-model plots\n",
    "    ep = range(len(train_losses))\n",
    "\n",
    "    plot(ep, train_losses, ylabel=\"Loss\",\n",
    "         name=f\"CNN-training-loss_{tag}_lr{lr}\")\n",
    "\n",
    "    plot(ep, val_no_soft_list, ylabel=\"Accuracy\",\n",
    "         name=f\"CNN-validation-accuracy_{tag}_no-softmax_lr{lr}\")\n",
    "\n",
    "    plot(ep, val_soft_list, ylabel=\"Accuracy\",\n",
    "         name=f\"CNN-validation-accuracy_{tag}_softmax_lr{lr}\")\n",
    "\n",
    "# Comparison plots (same figure)\n",
    "ep = range(epochs)\n",
    "\n",
    "plot_compare(\n",
    "    ep,\n",
    "    {\n",
    "        \"with pooling\": results[\"train_loss\"][\"with_pooling\"],\n",
    "        \"no pooling\": results[\"train_loss\"][\"no_pooling\"],\n",
    "    },\n",
    "    ylabel=\"Loss\",\n",
    "    title=\"Training Loss: pooling vs no pooling\",\n",
    "    filename=f\"COMPARE_training_loss_pool_vs_nopool_lr{lr}\"\n",
    ")\n",
    "\n",
    "plot_compare(\n",
    "    ep,\n",
    "    {\n",
    "        \"pool | no-soft\": results[\"val_acc_no_soft\"][\"with_pooling\"],\n",
    "        \"pool | soft\": results[\"val_acc_soft\"][\"with_pooling\"],\n",
    "        \"no-pool | no-soft\": results[\"val_acc_no_soft\"][\"no_pooling\"],\n",
    "        \"no-pool | soft\": results[\"val_acc_soft\"][\"no_pooling\"],\n",
    "    },\n",
    "    ylabel=\"Accuracy\",\n",
    "    title=\"Validation Accuracy: pooling vs no pooling (soft vs no-soft)\",\n",
    "    filename=f\"COMPARE_val_accuracy_pool_nopool_soft_nosoft_lr{lr}\"\n",
    ")\n",
    "\n",
    "global_time = time.time() - global_start\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DONE\")\n",
    "print(\"Total run time:\", f\"{global_time/60:.2f} min ({global_time:.2f} s)\")\n",
    "print(\"Params:\", results[\"params\"])\n",
    "print(\"Test:\", {\n",
    "    k: (results[\"test_acc_no_soft\"][k], results[\"test_acc_soft\"][k])\n",
    "    for k in results[\"test_acc_no_soft\"].keys()\n",
    "})"
   ],
   "id": "32bb9aa16b116d1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXPERIMENT: no_pooling\n",
      "======================================================================\n",
      "Trainable params: 26082896\n",
      "Epoch 001/200 | Loss: 0.8928 | ValAcc no-soft: 0.8452 | ValAcc soft: 0.8452 | Time: 14.11s\n",
      "Epoch 002/200 | Loss: 0.4624 | ValAcc no-soft: 0.8715 | ValAcc soft: 0.8715 | Time: 10.17s\n",
      "Epoch 003/200 | Loss: 0.3651 | ValAcc no-soft: 0.8931 | ValAcc soft: 0.8931 | Time: 11.29s\n",
      "Epoch 004/200 | Loss: 0.3194 | ValAcc no-soft: 0.8984 | ValAcc soft: 0.8984 | Time: 11.60s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[18]\u001B[39m\u001B[32m, line 48\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m     46\u001B[39m     t0 = time.time()\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m     tr_loss = \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muse_pool_flag\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpool_flag\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     49\u001B[39m     val_no_soft, val_soft = evaluate_both(val_loader, model, use_pool_flag=pool_flag)\n\u001B[32m     51\u001B[39m     train_losses.append(tr_loss)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36mtrain_epoch\u001B[39m\u001B[34m(loader, model, criterion, optimizer, use_pool_flag)\u001B[39m\n\u001B[32m      2\u001B[39m model.train()\n\u001B[32m      3\u001B[39m total_loss = \u001B[32m0.0\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mimgs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m.\u001B[49m\u001B[43msqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlong\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DeepLearningHomework1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    730\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    731\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    732\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m733\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    734\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    735\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    736\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    737\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    738\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    739\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DeepLearningHomework1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    787\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    788\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m789\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    790\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    791\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DeepLearningHomework1\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DeepLearningHomework1\\.venv\\Lib\\site-packages\\medmnist\\dataset.py:144\u001B[39m, in \u001B[36mMedMNIST2D.__getitem__\u001B[39m\u001B[34m(self, index)\u001B[39m\n\u001B[32m    141\u001B[39m     img = img.convert(\u001B[33m\"\u001B[39m\u001B[33mRGB\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    143\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m144\u001B[39m     img = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    146\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.target_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    147\u001B[39m     target = \u001B[38;5;28mself\u001B[39m.target_transform(target)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DeepLearningHomework1\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[39m, in \u001B[36mCompose.__call__\u001B[39m\u001B[34m(self, img)\u001B[39m\n\u001B[32m     93\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[32m     94\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transforms:\n\u001B[32m---> \u001B[39m\u001B[32m95\u001B[39m         img = \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     96\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DeepLearningHomework1\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1749\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1750\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1751\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\DeepLearningHomework1\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1757\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1758\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1759\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1760\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1761\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1762\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1764\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1765\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
